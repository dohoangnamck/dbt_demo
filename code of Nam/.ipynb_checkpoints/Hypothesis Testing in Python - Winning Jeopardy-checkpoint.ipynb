{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeopardy is a popular TV show in the US where participants answer questions to win money. In this project, we will work with the dataset of Jeopardy questions to figure out some patterns in the questions that could help win the game.\n",
    "\n",
    "![image](https://images2.minutemediacdn.com/image/upload/c_crop,w_4184,h_2353,x_0,y_297/c_fill,w_1440,ar_16:9,f_auto,q_auto,g_auto/images/GettyImages/mmsport/mentalfloss/01g2aftm5529evy4bpwa.jpg)\n",
    "\n",
    "\n",
    "The dataset can be found at this [link](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/).\n",
    "Each row in the dataset corresponds to one questions asked on a single episode. Description of a few columns:\n",
    "\n",
    "* Show Number - the Jeopardy episode number of the show this question was in.\n",
    "* Air Date - the date the episode aired.\n",
    "* Round - the round of Jeopardy that the question was asked in. Jeopardy has several rounds as each episode progresses.\n",
    "* Category - the category of the question.\n",
    "* Value - the number of dollars answering the question correctly is worth.\n",
    "* Question - the text of the question.\n",
    "* Answer - the text of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import bigrams\n",
    "from scipy.stats import chisquare,chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy= pd.read_csv(\"jeopardy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_number</th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   show_number    air_date      round                         category value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "\n",
       "                                            question      answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = jeopardy.columns\n",
    "jeopardy.columns = cols.str.strip().str.lower().str.replace(\" \",\"_\")\n",
    "jeopardy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   show_number  19999 non-null  int64 \n",
      " 1   air_date     19999 non-null  object\n",
      " 2   round        19999 non-null  object\n",
      " 3   category     19999 non-null  object\n",
      " 4   value        19663 non-null  object\n",
      " 5   question     19999 non-null  object\n",
      " 6   answer       19999 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize \n",
    "\n",
    "Let us normalize the questions and ansewrs columns to remove punctuations and convert all words to lower case. Some questions also contains html tags, so we will remove them as well. This way we can easily use the words for comparision later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    For the last 8 years of his life, Galileo was ...\n",
       "1    No. 2: 1912 Olympian; football star at Carlisl...\n",
       "2    The city of Yuma in this state has a record av...\n",
       "3    In 1963, live on \"The Art Linkletter Show\", th...\n",
       "4    Signer of the Dec. of Indep., framer of the Co...\n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"question\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_text(text):\n",
    "    text = text.lower()           #Convert str to lowercase\n",
    "    text = re.sub(\"[^a-zA-Z0-9/s]\",\" \",text)   #or ...,str(text)) if error\n",
    "    text = re.sub(\"/s+\",\" \",text)   #dấu câu\n",
    "    return text\n",
    "\n",
    "jeopardy[\"clean_question\"] = jeopardy[\"question\"].apply(normalize_text)\n",
    "jeopardy[\"clean_answer\"] = jeopardy[\"answer\"].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    for the last 8 years of his life  galileo was ...\n",
       "1    no  2  1912 olympian  football star at carlisl...\n",
       "2    the city of yuma in this state has a record av...\n",
       "3    in 1963  live on  the art linkletter show   th...\n",
       "4    signer of the dec  of indep   framer of the co...\n",
       "Name: clean_question, dtype: object"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"clean_question\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize value\n",
    "\n",
    "The value column must be numeric and the air_date a 'datetime' object rather than a string. So let us normalize these as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_value(value):\n",
    "    value = re.sub(\"[^a-zA-Z0-9/s]\", \"\",str(value))\n",
    "    if value != 'nan':\n",
    "        value = value\n",
    "    else:\n",
    "        value = 0\n",
    "    value = int(value)\n",
    "    return value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    200\n",
       "1    200\n",
       "2    200\n",
       "3    200\n",
       "4    200\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"value\"] = jeopardy[\"value\"].apply(normalize_value)\n",
    "jeopardy[\"value\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy[\"air_date\"] = pd.to_datetime(jeopardy[\"air_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2004-12-31\n",
       "1   2004-12-31\n",
       "2   2004-12-31\n",
       "3   2004-12-31\n",
       "4   2004-12-31\n",
       "Name: air_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"air_date\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Answers in Questions\n",
    "\n",
    "It would be helpful to figure two things when trying to analyze the game inorder to win it.\n",
    "\n",
    "* How often the answer is deducible from the question.\n",
    "* How often new questions are repeats of older questions.\n",
    "\n",
    "For the first question, we will see how many times on average do the answers appear or are mentioned of in the questions. For every answer we will check the corresponding questions to see if the answer or any part of the answer was in it. We will remove the Stopwords from the questions and answers as Stopwords are very common and can be misleading in our case.\n",
    "\n",
    "The basic idea is to find on average how many times do the questions contain the answers, so we will, for each answer check the corresponding questions and find the proportion of answer present in the question, we will then take its mean to get a general idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_matches(row):\n",
    "    split_answer = row[\"clean_answer\"].split()\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    if [\"the\",\"a\"] in split_answer:\n",
    "        split_answer.remove([\"the\",\"a\"])\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    match_count = 0\n",
    "    for answer in split_answer:\n",
    "        if answer in split_question:\n",
    "            match_count += 1\n",
    "    return match_count/len(split_answer)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_number</th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life  galileo was ...</td>\n",
       "      <td>copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no  2  1912 olympian  football star at carlisl...</td>\n",
       "      <td>jim thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   show_number   air_date      round                         category  value  \\\n",
       "0         4680 2004-12-31  Jeopardy!                          HISTORY    200   \n",
       "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES    200   \n",
       "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...    200   \n",
       "\n",
       "                                            question      answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "\n",
       "                                      clean_question clean_answer  \n",
       "0  for the last 8 years of his life  galileo was ...   copernicus  \n",
       "1  no  2  1912 olympian  football star at carlisl...   jim thorpe  \n",
       "2  the city of yuma in this state has a record av...      arizona  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy[\"answer_in_question\"] =  jeopardy.apply(count_matches,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      show_number   air_date             round  \\\n",
      "266          4931 2006-02-06  Double Jeopardy!   \n",
      "272          4931 2006-02-06  Double Jeopardy!   \n",
      "278          4931 2006-02-06  Double Jeopardy!   \n",
      "284          4931 2006-02-06  Double Jeopardy!   \n",
      "290          4931 2006-02-06  Double Jeopardy!   \n",
      "1137         1279 1990-03-08         Jeopardy!   \n",
      "1840         3113 1998-02-25  Double Jeopardy!   \n",
      "2347         4595 2004-07-23         Jeopardy!   \n",
      "2572         4220 2002-12-27         Jeopardy!   \n",
      "2818          422 1986-04-22         Jeopardy!   \n",
      "\n",
      "                            category  value  \\\n",
      "266   NOT A CURRENT NATIONAL CAPITAL    400   \n",
      "272   NOT A CURRENT NATIONAL CAPITAL    800   \n",
      "278   NOT A CURRENT NATIONAL CAPITAL   1200   \n",
      "284   NOT A CURRENT NATIONAL CAPITAL   1600   \n",
      "290   NOT A CURRENT NATIONAL CAPITAL   2000   \n",
      "1137                         PEANUTS    200   \n",
      "1840                    TAKE A GUESS    600   \n",
      "2347                    BIRD HUNTING    800   \n",
      "2572               THE PLANET URANUS    400   \n",
      "2818                  STUPID ANSWERS    300   \n",
      "\n",
      "                                               question              answer  \\\n",
      "266                    Ljubljana, Bratislava, Barcelona           Barcelona   \n",
      "272                             Istanbul, Ottawa, Amman            Istanbul   \n",
      "278                             Sofia, Sarajevo, Saigon              Saigon   \n",
      "284                               Bucharest, Bonn, Bern                Bonn   \n",
      "290            Belize City, Guatemala City, Panama City         Belize City   \n",
      "1137  Of a 25th, 30th or 40th anniversary, what \"Pea...    40th Anniversary   \n",
      "1840  Of a pogo stick injury, a dense winter fog or ...  a dense winter fog   \n",
      "2347  The third rail in a subway system is the one w...              a rail   \n",
      "2572  Of 84, 184 or 284, the length in years of one ...                  84   \n",
      "2818  In 1842, Richard Owen coined this word for “di...            dinosaur   \n",
      "\n",
      "                                         clean_question        clean_answer  \\\n",
      "266                    ljubljana  bratislava  barcelona           barcelona   \n",
      "272                             istanbul  ottawa  amman            istanbul   \n",
      "278                             sofia  sarajevo  saigon              saigon   \n",
      "284                               bucharest  bonn  bern                bonn   \n",
      "290            belize city  guatemala city  panama city         belize city   \n",
      "1137  of a 25th  30th or 40th anniversary  what  pea...    40th anniversary   \n",
      "1840  of a pogo stick injury  a dense winter fog or ...  a dense winter fog   \n",
      "2347  the third rail in a subway system is the one w...              a rail   \n",
      "2572  of 84  184 or 284  the length in years of one ...                  84   \n",
      "2818  in 1842  richard owen coined this word for  di...            dinosaur   \n",
      "\n",
      "      answer_in_question  \n",
      "266                  1.0  \n",
      "272                  1.0  \n",
      "278                  1.0  \n",
      "284                  1.0  \n",
      "290                  1.0  \n",
      "1137                 1.0  \n",
      "1840                 1.0  \n",
      "2347                 1.0  \n",
      "2572                 1.0  \n",
      "2818                 1.0  \n"
     ]
    }
   ],
   "source": [
    "print(jeopardy[jeopardy[\"answer_in_question\"]==1].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08632836042956549"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.answer_in_question.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only 8% the answer can be used for a question\n",
    "\n",
    "We found the mean to be - 8%\n",
    "This is actually a very small proportion (only 8.63%) of questions that contain some part of the answer in them. This tells us that just by this idea, we cannot win Jeopardy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate about repeat question\n",
    "Lets now try to see how often new questions are repeat of older ones. Now the dataset(sample) we are working with is just a representative of the population, hence we can only investigate this phenomenon and try to generalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy = jeopardy.sort_values('air_date',ascending = True)\n",
    "question_overlap = []\n",
    "terms_used = set()\n",
    "for i,row in jeopardy.iterrows():\n",
    "    split_question = row[\"clean_question\"].split()\n",
    "    for characters in split_question:\n",
    "        if len(characters) <=6:\n",
    "            split_question.remove(characters)\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "    for word in split_question:\n",
    "        terms_used.add(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "    question_overlap.append(match_count)\n",
    "            \n",
    "jeopardy[\"question_overlap\"] = question_overlap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19325    0.0\n",
       "19274    0.0\n",
       "19275    0.0\n",
       "19276    0.0\n",
       "19277    0.0\n",
       "        ... \n",
       "1916     1.0\n",
       "1917     1.0\n",
       "1918     1.0\n",
       "1971     0.9\n",
       "1922     1.0\n",
       "Name: question_overlap, Length: 19999, dtype: float64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"question_overlap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[282], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mterms_used\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md\u001b[49m \u001b[38;5;66;03m# xóa .d để hiện kết quả\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'set' object has no attribute 'd'"
     ]
    }
   ],
   "source": [
    "terms_used.d # xóa .d để hiện kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8259135539442273"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"question_overlap\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage is around - 82.59%. This is a considerable amount but we are only considering unigrams (word in tail have high rate because they match all the words which exit in terms_used). This high percentage can be because certain words repeat multiple times but not neccessarily in the same context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Value vs High Value Question\n",
    "\n",
    "The game is all about answering questions and earning money for every correct answer. So let us try to seggregate our analysis into high value questions and low value questions.\n",
    "\n",
    "Let us consider a threshold for high and low separation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_value(row):\n",
    "    value = 0\n",
    "    if row[\"value\"] > 750:\n",
    "        value = 1\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine which questions are high and low value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "jeopardy[\"high_value\"] =  jeopardy.apply(determine_value,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19325    0\n",
       "19301    0\n",
       "19302    0\n",
       "19303    0\n",
       "19304    0\n",
       "Name: high_value, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy[\"high_value\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Muốn lặp DF thì dùng iterrows để lặp các dòng\n",
    "## Tạo ra 1 function chỉ ra \"từ cần tìm\" trong câu hỏi xuất hiện ở high_value bao nhiêu lần, ở lơ_value bap nhiêu lần\n",
    "def count_usage(term):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138, 140)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_usage(\"term\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_number</th>\n",
       "      <th>air_date</th>\n",
       "      <th>round</th>\n",
       "      <th>category</th>\n",
       "      <th>value</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>answer_in_question</th>\n",
       "      <th>question_overlap</th>\n",
       "      <th>high_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19325</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Final Jeopardy!</td>\n",
       "      <td>U.S. PRESIDENTS</td>\n",
       "      <td>0</td>\n",
       "      <td>Adventurous 26th president, he was 1st to ride...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>adventurous 26th president  he was 1st to ride...</td>\n",
       "      <td>theodore roosevelt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>LABOR UNIONS</td>\n",
       "      <td>200</td>\n",
       "      <td>Notorious labor leader missing since '75</td>\n",
       "      <td>Jimmy Hoffa</td>\n",
       "      <td>notorious labor leader missing since  75</td>\n",
       "      <td>jimmy hoffa</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>1789</td>\n",
       "      <td>200</td>\n",
       "      <td>Washington proclaimed Nov. 26, 1789 this first...</td>\n",
       "      <td>Thanksgiving</td>\n",
       "      <td>washington proclaimed nov  26  1789 this first...</td>\n",
       "      <td>thanksgiving</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>TOURIST TRAPS</td>\n",
       "      <td>200</td>\n",
       "      <td>Both Ferde Grofe' &amp; the Colorado River dug thi...</td>\n",
       "      <td>the Grand Canyon</td>\n",
       "      <td>both ferde grofe    the colorado river dug thi...</td>\n",
       "      <td>the grand canyon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>10</td>\n",
       "      <td>1984-09-21</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>LITERATURE</td>\n",
       "      <td>200</td>\n",
       "      <td>Depending on the book, he could be a \"Jones\", ...</td>\n",
       "      <td>Tom</td>\n",
       "      <td>depending on the book  he could be a  jones   ...</td>\n",
       "      <td>tom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       show_number   air_date             round         category  value  \\\n",
       "19325           10 1984-09-21   Final Jeopardy!  U.S. PRESIDENTS      0   \n",
       "19301           10 1984-09-21  Double Jeopardy!     LABOR UNIONS    200   \n",
       "19302           10 1984-09-21  Double Jeopardy!             1789    200   \n",
       "19303           10 1984-09-21  Double Jeopardy!    TOURIST TRAPS    200   \n",
       "19304           10 1984-09-21  Double Jeopardy!       LITERATURE    200   \n",
       "\n",
       "                                                question              answer  \\\n",
       "19325  Adventurous 26th president, he was 1st to ride...  Theodore Roosevelt   \n",
       "19301           Notorious labor leader missing since '75         Jimmy Hoffa   \n",
       "19302  Washington proclaimed Nov. 26, 1789 this first...        Thanksgiving   \n",
       "19303  Both Ferde Grofe' & the Colorado River dug thi...    the Grand Canyon   \n",
       "19304  Depending on the book, he could be a \"Jones\", ...                 Tom   \n",
       "\n",
       "                                          clean_question        clean_answer  \\\n",
       "19325  adventurous 26th president  he was 1st to ride...  theodore roosevelt   \n",
       "19301           notorious labor leader missing since  75         jimmy hoffa   \n",
       "19302  washington proclaimed nov  26  1789 this first...        thanksgiving   \n",
       "19303  both ferde grofe    the colorado river dug thi...    the grand canyon   \n",
       "19304  depending on the book  he could be a  jones   ...                 tom   \n",
       "\n",
       "       answer_in_question  question_overlap  high_value  \n",
       "19325                 0.0          0.000000           0  \n",
       "19301                 0.0          0.000000           0  \n",
       "19302                 0.0          0.000000           0  \n",
       "19303                 0.0          0.200000           0  \n",
       "19304                 0.0          0.142857           0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM \n",
    "Now we have this, let us use the set words_used that we created earlier and observe the frequency of that word for high and low value questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "terms_used_list = list(terms_used)\n",
    "comparison_terms = random.sample(terms_used_list,10)\n",
    "\n",
    "observed_expected = []\n",
    "\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_usage(term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (3, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (18, 32),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (3, 1),\n",
       " (7, 6)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8714"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_value_count = jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "high_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11285"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_value_count = jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "low_value_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=398.0044304386353, pvalue=1.4974341819282966e-88),\n",
       " Power_divergenceResult(statistic=394.0516384553592, pvalue=1.0860309200456371e-87),\n",
       " Power_divergenceResult(statistic=398.0044304386353, pvalue=1.4974341819282966e-88),\n",
       " Power_divergenceResult(statistic=398.0044304386353, pvalue=1.4974341819282966e-88),\n",
       " Power_divergenceResult(statistic=396.0177217545414, pvalue=4.0535663695741305e-88),\n",
       " Power_divergenceResult(statistic=306.3957535555361, pvalue=1.3316807446800974e-68),\n",
       " Power_divergenceResult(statistic=398.005737606151, pvalue=1.4964533578241097e-88),\n",
       " Power_divergenceResult(statistic=398.005737606151, pvalue=1.4964533578241097e-88),\n",
       " Power_divergenceResult(statistic=392.0560688939945, pvalue=2.9530551178698244e-87),\n",
       " Power_divergenceResult(statistic=374.4406384922729, pvalue=2.0199695337039196e-83)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "chi_squared = []\n",
    "for obs in observed_expected:\n",
    "    total = jeopardy.value[0] + jeopardy.value[1]\n",
    "    total_prop = total/(jeopardy.shape[0])\n",
    "    high_value_expect = total_prop * high_value_count\n",
    "    low_value_expecet = total_prop * low_value_count\n",
    "    \n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expect = np.array([high_value_expect,low_value_expecet])\n",
    "    chi_squared.append(chisquare(observed,expect))\n",
    "    \n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For every word, the p-value is much higher than the threshold - 0.05. Hence we fail to reject the null hypothesis. This means that by examining these 5 words, we found no statistical significance suggesting that these words can help us identify the type of question (high-value or low-value) we are dealing with.\n",
    "\n",
    "The above result is only for 5 terms, and maybe inconclusive of the bigger picture. Thus let us try it again with more words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_test(observed_values,vocab):\n",
    "    high_value_count = np.count_nonzero(jeopardy .high_value == 1)\n",
    "    low_value_count = np.count_nonzero(jeopardy .high_value == 0)\n",
    "\n",
    "    total_rows = len(jeopardy)\n",
    "\n",
    "    for word,l in zip(vocab,observed_values):\n",
    "        total = sum(l)\n",
    "        total_prop = total / total_rows\n",
    "\n",
    "        expected_high = total_prop * high_value_count\n",
    "        expected_low = total_prop * low_value_count\n",
    "\n",
    "        observed = np.array([l[0],l[1]])\n",
    "        expected = np.array([expected_high,expected_low])\n",
    "\n",
    "        chi_squared[word] = chisquare(observed,expected)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1772': Power_divergenceResult(statistic=0.7721754541426672, pvalue=0.3795448984353682),\n",
       " '1824': Power_divergenceResult(statistic=1.6068893994548774, pvalue=0.2049296084582517),\n",
       " 'agent': Power_divergenceResult(statistic=0.5581074545503374, pvalue=0.4550237844510827),\n",
       " 'bernice': Power_divergenceResult(statistic=0.7721754541426672, pvalue=0.3795448984353682),\n",
       " 'citron': Power_divergenceResult(statistic=0.7721754541426672, pvalue=0.3795448984353682),\n",
       " 'goes': Power_divergenceResult(statistic=1.1660284442891515, pvalue=0.2802187935609849),\n",
       " 'isis': Power_divergenceResult(statistic=1.5443509082853344, pvalue=0.21397134128528295),\n",
       " 'ringlike': Power_divergenceResult(statistic=1.295042460408538, pvalue=0.25512076479610835),\n",
       " 'sass': Power_divergenceResult(statistic=1.295042460408538, pvalue=0.25512076479610835),\n",
       " 'vince': Power_divergenceResult(statistic=3.8851273812256135, pvalue=0.04871556686149284)}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared = {}\n",
    "chi_test(observed_expected ,comparison_terms )\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jeopardy!           9901\n",
       "Double Jeopardy!    9762\n",
       "Final Jeopardy!      335\n",
       "Tiebreaker             1\n",
       "Name: round, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy['round'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data and making its cross table with the value_level column, we can tell that Doube Jeopardy round holds the most high-value questions. But how do we know whether this phenomenon if just by chance (for this sample) or is this true for the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>high_value</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Double Jeopardy!</th>\n",
       "      <td>3507</td>\n",
       "      <td>6255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final Jeopardy!</th>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jeopardy!</th>\n",
       "      <td>7442</td>\n",
       "      <td>2459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tiebreaker</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "high_value           0     1\n",
       "round                       \n",
       "Double Jeopardy!  3507  6255\n",
       "Final Jeopardy!    335     0\n",
       "Jeopardy!         7442  2459\n",
       "Tiebreaker           1     0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_table = pd.crosstab(jeopardy['round'],jeopardy['high_value'])\n",
    "cross_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this purpose, let us perform a chi-square test using the scipy.stats.chi2_contingency function on the cross table.\n",
    "The null hypothesis is that there is no correlation between the rounds and the value level of the questions.\n",
    "\n",
    "The alternative hypothesis is that there exists some correlation between the rounds and value level of the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare,chi2_contingency\n",
    "chi_sq,p_value,dof,expected = chi2_contingency(cross_table)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "cross_table[0].plot.barh(align='center',color='#009999',label='low-level',width=0.25)\n",
    "cross_table[1].plot.barh(align='edge',color = '#ff9933',label='high-level',width=0.25)\n",
    "plt.legend()\n",
    "plt.yticks([])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel('Number of questions')\n",
    "plt.xlabel('Round')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://i.imgur.com/pATjOE8.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the cross table and the plot, we can then conclude the direction of the difference i.e. The first round Jeopardy hosts more low-level questions whereas the second round Double Jeopardy hosts more high-level questions. The final round Final Jeopardy and the Tiebreaker round host more of low-level questions.\n",
    "\n",
    "The category column has the topic for the question. We have analysed which rounds have a higher chance of having high-value questions. Now let us look into the categories (topics) and its correlation with the value levels. This was we can have an idea whether there exists a relationship/correlation between the value level and topic of question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TELEVISION          51\n",
       "U.S. GEOGRAPHY      50\n",
       "LITERATURE          45\n",
       "BEFORE & AFTER      40\n",
       "HISTORY             40\n",
       "AMERICAN HISTORY    40\n",
       "AUTHORS             39\n",
       "WORD ORIGINS        38\n",
       "WORLD CAPITALS      37\n",
       "BODIES OF WATER     36\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy .category.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the approach in finding the correlation between the words and value level of the questions. We will find the observed and expected frequencies of high-value and low-value questions for each category, to this we will apply a chi-square test to determine.\n",
    "\n",
    "The null hypothesis is that there is no correlation between the level of the value and the topic of the question.\n",
    "The alternative hypothesis is that there is a correlation between the level of the value and the topic of the question.\n",
    "\n",
    "In simple words we are checking for each category whether it is associated mostly with high-level questions or low-level questions. We will perform this analysis on the top 10 frequent topics in the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 42),\n",
       " (20, 30),\n",
       " (21, 24),\n",
       " (24, 16),\n",
       " (12, 28),\n",
       " (18, 22),\n",
       " (12, 27),\n",
       " (15, 23),\n",
       " (14, 23),\n",
       " (10, 26)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catgs = jeopardy.category.value_counts().sort_values(ascending=False)[:10].index\n",
    "\n",
    "def observed(catg):\n",
    "    high_count = 0\n",
    "    low_count = 0\n",
    "    \n",
    "    for i,row in jeopardy.iterrows():\n",
    "        if row.category == catg:\n",
    "            if row.high_value == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "                \n",
    "    return high_count,low_count\n",
    "\n",
    "observed_values = []\n",
    "for catg in catgs:\n",
    "    observed_values.append(observed(catg))\n",
    "    \n",
    "observed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMERICAN HISTORY': Power_divergenceResult(statistic=0.03316692443543142, pvalue=0.855490212383109),\n",
       " 'AUTHORS': Power_divergenceResult(statistic=2.6000518043290746, pvalue=0.10686022199140573),\n",
       " 'BEFORE & AFTER': Power_divergenceResult(statistic=4.390534336396016, pvalue=0.03613898538801975),\n",
       " 'BODIES OF WATER': Power_divergenceResult(statistic=3.652634806702691, pvalue=0.05598058556613405),\n",
       " 'HISTORY': Power_divergenceResult(statistic=2.9967917586670154, pvalue=0.08342957570170428),\n",
       " 'LITERATURE': Power_divergenceResult(statistic=0.17526192502981316, pvalue=0.6754770906301193),\n",
       " 'TELEVISION': Power_divergenceResult(statistic=13.941489027465813, pvalue=0.00018858955620803958),\n",
       " 'U.S. GEOGRAPHY': Power_divergenceResult(statistic=0.25949785783631446, pvalue=0.6104653431793821),\n",
       " 'WORD ORIGINS': Power_divergenceResult(statistic=0.2596149692997901, pvalue=0.6103847994683275),\n",
       " 'WORLD CAPITALS': Power_divergenceResult(statistic=0.4948415535552552, pvalue=0.4817755106192815)}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared = {}\n",
    "\n",
    "def chi_test(observed_values,catgs):\n",
    "    high_value_count = np.count_nonzero(jeopardy.high_value == 1)\n",
    "    low_value_count = np.count_nonzero(jeopardy.high_value == 0)\n",
    "\n",
    "    total_rows = len(jeopardy)\n",
    "\n",
    "    for catg,l in zip(catgs,observed_values):\n",
    "        total = sum(l)\n",
    "        total_prop = total / total_rows\n",
    "\n",
    "        expected_high = total_prop * high_value_count\n",
    "        expected_low = total_prop * low_value_count\n",
    "\n",
    "        observed = np.array([l[0],l[1]])\n",
    "        expected = np.array([expected_high,expected_low])\n",
    "\n",
    "        chi_squared[catg] = chisquare(observed,expected)\n",
    "    \n",
    "chi_test(observed_values,catgs)\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the majority of topics do not have p_value <= 0.05, meaning for these topics we fail to reject the null hypothesis. However, for two topics - TELEVISION and BEFORE & AFTER, the null hypothesis is rejected and hence can be said that it does have a correlation with the value levels.\n",
    "\n",
    "We have only performed these tests for the top 10 most frequent categories (topics) in the data. Let us perform the same for the top 20 categories (topics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TELEVISION', 'U.S. GEOGRAPHY', 'LITERATURE', 'BEFORE & AFTER',\n",
      "       'HISTORY', 'AMERICAN HISTORY', 'AUTHORS', 'WORD ORIGINS',\n",
      "       'WORLD CAPITALS', 'BODIES OF WATER', 'SPORTS', 'RHYME TIME',\n",
      "       'SCIENCE & NATURE', 'SCIENCE', 'MAGAZINES', 'WORLD GEOGRAPHY',\n",
      "       'WORLD HISTORY', 'ANNUAL EVENTS', 'HISTORIC NAMES',\n",
      "       'IN THE DICTIONARY'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(9, 42),\n",
       " (20, 30),\n",
       " (21, 24),\n",
       " (24, 16),\n",
       " (12, 28),\n",
       " (18, 22),\n",
       " (12, 27),\n",
       " (15, 23),\n",
       " (14, 23),\n",
       " (10, 26),\n",
       " (7, 29),\n",
       " (12, 23),\n",
       " (21, 14),\n",
       " (21, 14),\n",
       " (12, 23),\n",
       " (11, 22),\n",
       " (10, 22),\n",
       " (11, 21),\n",
       " (15, 17),\n",
       " (22, 9)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catgs = jeopardy.category.value_counts().sort_values(ascending=False)[:20].index\n",
    "\n",
    "observed_values = []\n",
    "for catg in catgs:\n",
    "    observed_values.append(observed(catg))\n",
    "    \n",
    "print(catgs)\n",
    "observed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMERICAN HISTORY': Power_divergenceResult(statistic=0.03316692443543142, pvalue=0.855490212383109),\n",
       " 'ANNUAL EVENTS': Power_divergenceResult(statistic=1.1009222808234171, pvalue=0.2940637912962565),\n",
       " 'AUTHORS': Power_divergenceResult(statistic=2.6000518043290746, pvalue=0.10686022199140573),\n",
       " 'BEFORE & AFTER': Power_divergenceResult(statistic=4.390534336396016, pvalue=0.03613898538801975),\n",
       " 'BODIES OF WATER': Power_divergenceResult(statistic=3.652634806702691, pvalue=0.05598058556613405),\n",
       " 'HISTORIC NAMES': Power_divergenceResult(statistic=0.14197686997349648, pvalue=0.7063235918777161),\n",
       " 'HISTORY': Power_divergenceResult(statistic=2.9967917586670154, pvalue=0.08342957570170428),\n",
       " 'IN THE DICTIONARY': Power_divergenceResult(statistic=9.462798794299626, pvalue=0.002096808976711425),\n",
       " 'LITERATURE': Power_divergenceResult(statistic=0.17526192502981316, pvalue=0.6754770906301193),\n",
       " 'MAGAZINES': Power_divergenceResult(statistic=1.2276265582942991, pvalue=0.26786911298547267),\n",
       " 'RHYME TIME': Power_divergenceResult(statistic=1.2276265582942991, pvalue=0.26786911298547267),\n",
       " 'SCIENCE': Power_divergenceResult(statistic=3.8417175443465155, pvalue=0.04999228562898841),\n",
       " 'SCIENCE & NATURE': Power_divergenceResult(statistic=3.8417175443465155, pvalue=0.04999228562898841),\n",
       " 'SPORTS': Power_divergenceResult(statistic=8.523795485944486, pvalue=0.00350532671847749),\n",
       " 'TELEVISION': Power_divergenceResult(statistic=13.941489027465813, pvalue=0.00018858955620803958),\n",
       " 'U.S. GEOGRAPHY': Power_divergenceResult(statistic=0.25949785783631446, pvalue=0.6104653431793821),\n",
       " 'WORD ORIGINS': Power_divergenceResult(statistic=0.2596149692997901, pvalue=0.6103847994683275),\n",
       " 'WORLD CAPITALS': Power_divergenceResult(statistic=0.4948415535552552, pvalue=0.4817755106192815),\n",
       " 'WORLD GEOGRAPHY': Power_divergenceResult(statistic=1.4070623489237597, pvalue=0.23554467279401614),\n",
       " 'WORLD HISTORY': Power_divergenceResult(statistic=1.9761614326845232, pvalue=0.1597953765739848)}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared = {}\n",
    "chi_test(observed_values,catgs)\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have new additions to our list of topics that have correlation with the value levels, they are - SPORTS, SCIENCE, SCIENCE & NATURE, BIRDS and the ones from previous analysis as well as this, TELEVISION and BEFORE & AFTER.\n",
    "\n",
    "Let us make a cross table for these topics, to understand the frequencies of these topics with respect to the value level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>high_value</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BEFORE &amp; AFTER</th>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRDS</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCIENCE</th>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCIENCE &amp; NATURE</th>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPORTS</th>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TELEVISION</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "high_value         0   1\n",
       "category                \n",
       "BEFORE & AFTER    16  24\n",
       "BIRDS             26   5\n",
       "SCIENCE           14  21\n",
       "SCIENCE & NATURE  14  21\n",
       "SPORTS            29   7\n",
       "TELEVISION        42   9"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catg_interest = [\n",
    "    'SPORTS',\n",
    "    'SCIENCE',\n",
    "    'SCIENCE & NATURE',\n",
    "    'BIRDS',\n",
    "    'TELEVISION',\n",
    "    'BEFORE & AFTER'\n",
    "]\n",
    "\n",
    "subset = jeopardy[jeopardy.category.isin(catg_interest)]\n",
    "cross_table = pd.crosstab(subset.category,subset.high_value)\n",
    "cross_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "cross_table[0].plot.bar(align='center',color='#009999',label='low-level',width=0.25)\n",
    "cross_table[1].plot.bar(align='edge',color = '#ff9933',label='high-level',width=0.25)\n",
    "plt.legend()\n",
    "plt.yticks([])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel('Number of questions')\n",
    "plt.xlabel('Topics')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/HnqE2s9.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the cross table, the plot and the p_values obtained from before, we can say that the topics SPORTS, TELEVISION, BIRDS have a higher chance of being low-level questions, whereas the topics BEFORE & AFTER, SCIENCE and SCIENCE & NATURE have a higher chance of being high-level questions.\n",
    "\n",
    "From our analysis, we can conclude :-\n",
    "\n",
    "1. The answers are hardly hidden in the questions and hence the participant has to be revised with all categories (topics).\n",
    "\n",
    "2. The repetition of questions is rare, the participant must not rely on reading previous questions only to win the game.\n",
    "\n",
    "3. No relationship was found between the level of the question (>750 or <750 dollars) and the words present in the questions. Thus the participant cannot estimate the level of the question with respect to words in  the question.\n",
    "\n",
    "4. The first round, Jeopardy! hosts mostly low-level (<750 dollars) questions. Whereas the second round    Double Jeopardy! hosts high-level (>750 dollars) questions. Participant's aim to win more money can utilize these findings and play accordingly.\n",
    "\n",
    "5. The categories (topics) - SPORTS, TELEVISION and BIRDS have a higher chance of having low-level (<750 dollars) questions, whereas the categories (topics) BEFORE & AFTER, SCIENCE and SCIENCE & NATURE have a highe chance of having high-level (> 750 dollars) questions. \n",
    "\n",
    "From the above conclusions, the participant can accordingly prepare and choose to answer questions in the game in order to win more money and overall be successful in the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
